{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawHisTransDF=pd.read_csv('Historical-transaction-data.csv')\n",
    "rawStoreInfDF=pd.read_csv('Store-info.csv')\n",
    "rawTestDF=pd.read_csv('Testing-data.csv')\n",
    "rawHisTransDF.dropna(subset=['item_description','invoice_id'], inplace=True)\n",
    "rawHisTransDF=rawHisTransDF.drop_duplicates()\n",
    "# convert the date string column to datetime\n",
    "rawHisTransDF['transaction_date'] = pd.to_datetime(rawHisTransDF['transaction_date'], format='%Y/%m/%d').dt.date\n",
    "rawHisTransDF.dropna(subset=['item_description','invoice_id'], inplace=True)\n",
    "rawHisTransDF=rawHisTransDF.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawHisTransDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "rawHisTransDF['item_description'] = le.fit_transform(rawHisTransDF['item_description'])\n",
    "rawHisTransDF['customer_id'] = le.fit_transform(rawHisTransDF['customer_id'])\n",
    "rawHisTransDF['shop_id'] = rawHisTransDF['shop_id'].str.replace(r'^SHOP', '').astype(int)\n",
    "rawStoreInfDF['shop_id'] = rawStoreInfDF['shop_id'].str.replace(r'^SHOP', '').astype(int)\n",
    "rawStoreInfDF['shop_profile'] = rawStoreInfDF['shop_profile'].replace({'High': 3, 'Moderate': 2, 'Low': 1})\n",
    "rawStoreInfDF['shop_profile'] = rawStoreInfDF['shop_profile'].fillna(0.0).astype(int)\n",
    "rawHisTransDF['invoice_id'] = rawHisTransDF['invoice_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawHisTransDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawHisTransDF['payment']=rawHisTransDF['item_price']*rawHisTransDF['quantity_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by the 'group' column and get the size of each group\n",
    "transactions_by_shop = rawHisTransDF.groupby('shop_id').size().reset_index()\n",
    "\n",
    "# rename columns of the new dataframe\n",
    "transactions_by_shop.columns = ['shop_id', 'num_of_transactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average price for each item type sold by each shop\n",
    "avg_prices = rawHisTransDF.groupby(['shop_id', 'item_description'])['item_price'].mean().reset_index()\n",
    "\n",
    "# Rename 'price' column to 'avg_price'\n",
    "avg_prices.columns = ['shop_id', 'item_description','times']\n",
    "\n",
    "# Merge the average prices back into the original DataFrame\n",
    "# merged_df = pd.merge(merged_df, avg_prices, on=['shop_id', 'item_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawHisTransDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rawHisTransDF.groupby(['shop_id'])['payment'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging two dataframes on 'key' column\n",
    "merged_df = pd.merge(rawStoreInfDF, result, on='shop_id')\n",
    "merged_df = pd.merge(transactions_by_shop,result,on='shop_id')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawHisTransDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by 'group' column and find number of unique values in 'value' column for each group\n",
    "result = rawHisTransDF.groupby('shop_id')['customer_id'].apply(lambda x: len(set(x))).reset_index()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = rawHisTransDF['item_description'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by the 'group' column and get the size of each group\n",
    "temp = rawHisTransDF.groupby(['shop_id','item_description']).size().reset_index()\n",
    "\n",
    "# rename columns of the new dataframe\n",
    "temp.columns = ['shop_id', 'item_description','times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate average price for each item type sold by each shop\n",
    "# avg_prices = rawHisTransDF.groupby(['shop_id', 'item_description'])['item_price'].mean().reset_index()\n",
    "\n",
    "# # Rename 'price' column to 'avg_price'\n",
    "# avg_prices.columns = ['shop_id', 'item_description','times']\n",
    "\n",
    "# # Merge the average prices back into the original DataFrame\n",
    "# # merged_df = pd.merge(merged_df, avg_prices, on=['shop_id', 'item_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv('final1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the dataframe to make item_description values as columns\n",
    "pivoted_df = temp.pivot(index='shop_id', columns='item_description', values='times')\n",
    "\n",
    "# fill NaN values with 0\n",
    "pivoted_df.fillna(0, inplace=True)\n",
    "\n",
    "# resetting the index\n",
    "pivoted_df = pivoted_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the dataframe to make item_description values as columns\n",
    "pivoted_df_avg = avg_prices.pivot(index='shop_id', columns='item_description', values='times')\n",
    "\n",
    "# fill NaN values with 0\n",
    "pivoted_df_avg.fillna(0, inplace=True)\n",
    "\n",
    "# resetting the index\n",
    "pivoted_df_avg = pivoted_df_avg.reset_index()\n",
    "pivoted_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename every column except the first two columns with an incrementing value\n",
    "for i, col in enumerate(pivoted_df_avg.columns[2:], start=1):\n",
    "    pivoted_df_avg = pivoted_df_avg.rename(columns={col: f'Column_{i}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df_avg.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawStoreInfDF=pd.merge(rawStoreInfDF,pivoted_df_avg,on='shop_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df.to_csv('final3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawStoreInfDF=pd.merge(rawStoreInfDF,pivoted_df, on='shop_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawStoreInfDF=pd.merge(rawStoreInfDF,result, on='shop_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawStoreInfDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all float columns to integer columns\n",
    "rawStoreInfDF = rawStoreInfDF.applymap(lambda x: int(x) if isinstance(x, float) else x)\n",
    "rawStoreInfDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawStoreInfDF=pd.merge(rawStoreInfDF,merged_df, on='shop_id')\n",
    "rawStoreInfDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawStoreInfDF.to_csv('storeinfo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawStoreInfDF=pd.read_csv('storeinfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawStoreInfDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawStoreInfDF['payment']=rawStoreInfDF['payment']/rawStoreInfDF['shop_area_sq_ft']\n",
    "rawStoreInfDF=rawStoreInfDF.drop('shop_area_sq_ft',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into two based on column B\n",
    "TestDF = rawStoreInfDF[rawStoreInfDF['shop_profile'] == 0].drop(['shop_profile'], axis=1)\n",
    "TrainDF = rawStoreInfDF[rawStoreInfDF['shop_profile'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Fulldata into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "column_name = 'shop_id'\n",
    "unique_categories = TrainDF[column_name].nunique()\n",
    "categories_in_dataset_1 = int(unique_categories * 0.9)\n",
    "categories_in_dataset_2 = unique_categories - categories_in_dataset_1\n",
    "dataset_1_categories = TrainDF[column_name].unique()[:categories_in_dataset_1]\n",
    "dataset_2_categories = TrainDF[column_name].unique()[categories_in_dataset_1:]\n",
    "\n",
    "train_data = TrainDF[TrainDF[column_name].isin(dataset_1_categories)]\n",
    "test_data = TrainDF[TrainDF[column_name].isin(dataset_2_categories)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train_data, test_data = train_test_split(TrainDF, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectedResult=test_data[['shop_id','shop_profile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_id_x_test = test_data['shop_id']\n",
    "shop_id_x_TestDF = TestDF['shop_id']\n",
    "TestDF=TestDF.drop('shop_id',axis=1)\n",
    "train_data=train_data.drop('shop_id', axis=1)\n",
    "test_data=test_data.drop('shop_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_data.drop(['shop_profile'], axis=1)\n",
    "y_train=train_data['shop_profile']\n",
    "X_test= test_data.drop(['shop_profile'], axis=1)\n",
    "y_test=test_data['shop_profile']\n",
    "X_testres = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "# # Define the decision tree classifier\n",
    "# dtc = DecisionTreeClassifier()\n",
    "\n",
    "# # Define the hyperparameters to tune\n",
    "# params = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [2, 3, 4, 5, 6],\n",
    "#     'min_samples_split': [2, 3, 4, 5],\n",
    "#     'min_samples_leaf': [1, 2, 3, 4],\n",
    "# }\n",
    "\n",
    "# # Perform grid search to find the best hyperparameters\n",
    "# grid_search = GridSearchCV(dtc, param_grid=params, cv=5)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding score\n",
    "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "# print(\"Best score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Define the logistic regression model\n",
    "# model_random = RandomForestClassifier(max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=10)\n",
    "\n",
    "# # Train the model on the training data\n",
    "# model_random.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the testing data\n",
    "# predictions = model_random.predict(X_test)\n",
    "# predictions_Test_randomforest=model_random.predict(TestDF)\n",
    "\n",
    "# accu = accuracy_score(y_test, predictions)\n",
    "\n",
    "# print(accu)\n",
    "# # print(f1_score(y_test, predictions, average=None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predDf=pd.DataFrame(predictions, columns=['shop_profile'])\n",
    "# predDf_Test_randomforest=pd.DataFrame(predictions_Test_randomforest, columns=['shop_profile'])\n",
    "# shop_id_x_test=shop_id_x_test.reset_index()\n",
    "# shop_id_x_TestDF=shop_id_x_TestDF.reset_index()\n",
    "# shop_id_x_TestDF=shop_id_x_TestDF.drop('index',axis=1)\n",
    "# # Concatenate DataFrames\n",
    "# concatenatedRes_df = pd.concat([shop_id_x_test, predDf], axis=1)\n",
    "# # concatenatedRes_df = pd.concat([concatenatedRes_df, shop_id_x_test], axis=1)\n",
    "# # concatenated_df = pd.concat([shop_id_x_test, predDf], ignore_index=True)\n",
    "# concatenatedRes_df_random = pd.concat([shop_id_x_TestDF, predDf_Test_randomforest], axis=1)\n",
    "# expectedResult=expectedResult['shop_profile']\n",
    "# concatenatedRes_df=concatenatedRes_df['shop_profile']\n",
    "# # Calculate F1 score for each class\n",
    "# f1_class0 = f1_score(expectedResult, concatenatedRes_df, labels=[1], average='weighted')\n",
    "# f1_class1 = f1_score(expectedResult, concatenatedRes_df, labels=[2], average='weighted')\n",
    "# f1_class2 = f1_score(expectedResult, concatenatedRes_df, labels=[3], average='weighted')\n",
    "\n",
    "# # Calculate average F1 score\n",
    "# f1_average = (f1_class0 + f1_class1 + f1_class2) / 3\n",
    "\n",
    "# print(f\"F1 score for class 0: {f1_class0:.2f}\")\n",
    "# print(f\"F1 score for class 1: {f1_class1:.2f}\")\n",
    "# print(f\"F1 score for class 2: {f1_class2:.2f}\")\n",
    "# print(f\"Average F1 score: {f1_average:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the logistic regression model\n",
    "model_random = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "model_random.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = model_random.predict(X_test)\n",
    "predictions_Test_randomforest=model_random.predict(TestDF)\n",
    "\n",
    "accu = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(accu)\n",
    "# print(f1_score(y_test, predictions, average=None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf=pd.DataFrame(predictions, columns=['shop_profile'])\n",
    "predDf_Test_randomforest=pd.DataFrame(predictions_Test_randomforest, columns=['shop_profile'])\n",
    "shop_id_x_test=shop_id_x_test.reset_index()\n",
    "shop_id_x_TestDF=shop_id_x_TestDF.reset_index()\n",
    "shop_id_x_TestDF=shop_id_x_TestDF.drop('index',axis=1)\n",
    "# Concatenate DataFrames\n",
    "concatenatedRes_df = pd.concat([shop_id_x_test, predDf], axis=1)\n",
    "# concatenatedRes_df = pd.concat([concatenatedRes_df, shop_id_x_test], axis=1)\n",
    "# concatenated_df = pd.concat([shop_id_x_test, predDf], ignore_index=True)\n",
    "concatenatedRes_df_random = pd.concat([shop_id_x_TestDF, predDf_Test_randomforest], axis=1)\n",
    "expectedResult=expectedResult['shop_profile']\n",
    "concatenatedRes_df=concatenatedRes_df['shop_profile']\n",
    "# Calculate F1 score for each class\n",
    "f1_class0 = f1_score(expectedResult, concatenatedRes_df, labels=[1], average='weighted')\n",
    "f1_class1 = f1_score(expectedResult, concatenatedRes_df, labels=[2], average='weighted')\n",
    "f1_class2 = f1_score(expectedResult, concatenatedRes_df, labels=[3], average='weighted')\n",
    "\n",
    "# Calculate average F1 score\n",
    "f1_average = (f1_class0 + f1_class1 + f1_class2) / 3\n",
    "\n",
    "print(f\"F1 score for class 0: {f1_class0:.2f}\")\n",
    "print(f\"F1 score for class 1: {f1_class1:.2f}\")\n",
    "print(f\"F1 score for class 2: {f1_class2:.2f}\")\n",
    "print(f\"Average F1 score: {f1_average:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Train the first set of models\n",
    "# model1 = LogisticRegression()\n",
    "# model1.fit(X_train, y_train)\n",
    "\n",
    "# model2 = RandomForestClassifier(max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=10)\n",
    "# model2.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the testing set using the first set of models\n",
    "# y_pred_1 = model1.predict(X_test)\n",
    "# y_pred_2 = model2.predict(X_test)\n",
    "# y_pred_1_test = model1.predict(TestDF)\n",
    "# y_pred_2_test = model2.predict(TestDF)\n",
    "\n",
    "# # Stack the predictions from the first set of models\n",
    "# X_stack = np.column_stack((y_pred_1, y_pred_2))\n",
    "# X_stack_test = np.column_stack((y_pred_1_test,y_pred_2_test))\n",
    "\n",
    "# # Train the final model on the stacked predictions\n",
    "# final_model = LogisticRegression()\n",
    "# final_model.fit(X_stack, y_test)\n",
    "\n",
    "# # Make predictions on the testing set using the final model\n",
    "# y_pred_int = final_model.predict(X_stack)\n",
    "# y_pred_int_test = final_model.predict(X_stack_test)\n",
    "\n",
    "# # Calculate the accuracy of the final predictions\n",
    "# accuracy = accuracy_score(y_test, y_pred_int)\n",
    "# print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace({1: 0, 2: 1, 3: 2})\n",
    "y_test = y_test.replace({1: 0, 2: 1, 3: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Train the first set of models\n",
    "# model1 = xgb.XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "# model1.fit(X_train, y_train)\n",
    "\n",
    "# model2 = RandomForestClassifier(max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=10)\n",
    "# model2.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the testing set using the first set of models\n",
    "# y_pred_1 = model1.predict(X_test)\n",
    "# y_pred_2 = model2.predict(X_test)\n",
    "# y_pred_1_test = model1.predict(TestDF)\n",
    "# y_pred_2_test = model2.predict(TestDF)\n",
    "\n",
    "# # Stack the predictions from the first set of models\n",
    "# X_stack = np.column_stack((y_pred_1, y_pred_2))\n",
    "# X_stack_test = np.column_stack((y_pred_1_test,y_pred_2_test))\n",
    "\n",
    "# # Train the final model on the stacked predictions\n",
    "# final_model = xgb.XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "# final_model.fit(X_stack, y_test)\n",
    "\n",
    "# # Make predictions on the testing set using the final model\n",
    "# y_pred_int = final_model.predict(X_stack)\n",
    "# y_pred_int_test = final_model.predict(X_stack_test)\n",
    "\n",
    "# # Calculate the accuracy of the final predictions\n",
    "# accuracy = accuracy_score(y_test, y_pred_int)\n",
    "# print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# import numpy as np\n",
    "\n",
    "# # Train the first set of models\n",
    "# model1 = KNeighborsClassifier(n_neighbors=10)\n",
    "# model1.fit(X_train, y_train)\n",
    "\n",
    "# model2 = RandomForestClassifier(max_depth=100, min_samples_leaf=5, min_samples_split=2, n_estimators=25)\n",
    "# model2.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the testing set using the first set of models\n",
    "# y_pred_1 = model1.predict(X_test)\n",
    "# y_pred_2 = model2.predict(X_test)\n",
    "# y_pred_1_test = model1.predict(TestDF)\n",
    "# y_pred_2_test = model2.predict(TestDF)\n",
    "\n",
    "# # Stack the predictions from the first set of models\n",
    "# X_stack = np.column_stack((y_pred_1, y_pred_2))\n",
    "# X_stack_test = np.column_stack((y_pred_1_test,y_pred_2_test))\n",
    "\n",
    "# # Train the final model on the stacked predictions\n",
    "# final_model = KNeighborsClassifier(n_neighbors=5)\n",
    "# final_model.fit(X_stack, y_test)\n",
    "\n",
    "# # Make predictions on the testing set using the final model\n",
    "# y_pred_int = final_model.predict(X_stack)\n",
    "# y_pred_int_test = final_model.predict(X_stack_test)\n",
    "\n",
    "# # Calculate the accuracy of the final predictions\n",
    "# accuracy = accuracy_score(y_test, y_pred_int)\n",
    "# print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create confusion matrix\n",
    "matrix = confusion_matrix(expectedResult, concatenatedRes_df)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "sns.heatmap(matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedRes_df_random['shop_profile'] = concatenatedRes_df_random['shop_profile'].replace({3: 'High', 2: 'Moderate', 1: 'Low'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedRes_df_random.to_csv('day3_1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
